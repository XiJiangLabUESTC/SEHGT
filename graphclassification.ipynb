{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f37e9518-384d-4b18-b527-f3abc382a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "import dgl\n",
    "import os\n",
    "import pandas as pd\n",
    "from dgl.data import DGLDataset\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from timm.scheduler.cosine_lr import CosineLRScheduler\n",
    "from timm.loss import LabelSmoothingCrossEntropy\n",
    "import random\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score,f1_score,accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import datetime\n",
    "device = th.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b787e142",
   "metadata": {},
   "outputs": [],
   "source": [
    "oridir = os.path.dirname(__file__)\n",
    "datainfo_dir = os.path.join(oridir,'DataInfo.csv')\n",
    "funcdata_dir = os.path.join(oridir,'data/RawFunc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c43ca89-ef79-45c9-88cf-1845fb887abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(DGLDataset):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self,func_atlas,datainfo,feat_root,removeAlone=True):\n",
    "        super(MyDataset,self).__init__(\n",
    "            name='ABIDE I'\n",
    "        )\n",
    "        self.func_atlas = func_atlas\n",
    "        self.datainfo = datainfo\n",
    "        self.feat_root = feat_root\n",
    "        self.getGraphStructual()\n",
    "        self.removeAlone=removeAlone  \n",
    "    def process(self):\n",
    "        pass\n",
    "    def save(self):\n",
    "        pass\n",
    "    def load(self):\n",
    "        pass\n",
    "        \n",
    "    def __getitem__(self,idx):\n",
    "        try:\n",
    "            label = self.datainfo.loc[idx,'LABEL']\n",
    "        except:\n",
    "            print(idx)\n",
    "            label = 0 \n",
    "        label = th.tensor(label).long()\n",
    "        subid = self.datainfo.loc[idx,'SubID']\n",
    "        nfeat = os.path.join(self.feat_root,str(subid)+'.npy')\n",
    "        nfeat = th.from_numpy(np.load(nfeat)).float()\n",
    "        graph = dgl.heterograph(self.graphS)\n",
    "        graph.ndata['feat'] = nfeat\n",
    "        return graph,label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.datainfo)\n",
    "    \n",
    "    def getGraphStructual(self):\n",
    "        graphdata = {}\n",
    "        graphnode = []\n",
    "        for index,func in enumerate(self.func_atlas):\n",
    "            same_net_i,same_net_j=[],[]\n",
    "            for i in range(func.shape[0]):\n",
    "                for j in range(func.shape[0]):\n",
    "                    if (func[i] == True) and (func[j] == True):\n",
    "                        same_net_i.append(i)\n",
    "                        same_net_j.append(j)\n",
    "                        if i not in graphnode:\n",
    "                            graphnode.append(i)\n",
    "            same_net_i = th.tensor(same_net_i,dtype=th.int32)\n",
    "            same_net_j = th.tensor(same_net_j,dtype=th.int32)\n",
    "            graphdata[('area','func'+str(index),'area')] = (same_net_i,same_net_j)\n",
    "        self.graphS  = graphdata\n",
    "        self.graphN = {'area':graphnode}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f443ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Runer(object):\n",
    "    def __init__(self,args_model,args_train=None):\n",
    "        self.args_train = args_train\n",
    "        self.args_model = args_model\n",
    "        if args_model['model_name'] in ['HGT','HAN','SEHGT']:\n",
    "            self.modeltype= args_model['model_name']\n",
    "        else:\n",
    "            self.modeltype = 'HGT'\n",
    "        self.template = np.load(args_train['template'])\n",
    "        self.dataload()\n",
    "\n",
    "    def init_weight(self):\n",
    "        self.setup_seed(2022)\n",
    "        self.init_model()\n",
    "        self.init_optimizer()\n",
    "        self.init_lossfn()\n",
    "\n",
    "    def dataload(self):\n",
    "        self.RSN=range(self.template.shape[0])\n",
    "        self.func_atlas = [self.template[i] for i in self.RSN]\n",
    "        self.datainfo = pd.read_csv(datainfodir)\n",
    "        self.KFold = KFold(n_splits=5,random_state=2022,shuffle=True).split(self.datainfo)\n",
    "\n",
    "\n",
    "    def init_data(self,train_split,test_split):\n",
    "        train_info = self.datainfo.loc[train_split]\n",
    "        test_info = self.datainfo.loc[test_split]\n",
    "        train_info = train_info.reset_index(drop=True)\n",
    "        test_info = test_info.reset_index(drop=True)\n",
    "        feat_root = funcdata_dir\n",
    "        self.traindata = MyDataset(self.func_atlas,train_info,feat_root,removeAlone=True)\n",
    "        self.testdata = MyDataset(self.func_atlas,test_info,feat_root,removeAlone=True)\n",
    "        self.train_loader = GraphDataLoader(self.traindata,batch_size = 16)\n",
    "        self.test_loader = GraphDataLoader(self.testdata,batch_size = 16)\n",
    "        print('Train:{}  Test:{}  Nodes:{}'.format(len(self.traindata),len(self.testdata),len(self.traindata.graphN['area'])))\n",
    "\n",
    "    def setup_seed(self,seed=42):\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        \n",
    "    def init_model(self):\n",
    "        if self.modeltype =='SEHGT':\n",
    "            node_dict = {'area':0}\n",
    "            edge_dict={'func'+str(i):i for i in range(len(self.RSN))}\n",
    "            args = self.args_model\n",
    "            from ModelsForGraph import SEHGT\n",
    "            self.model=SEHGT(\n",
    "                node_dict,\n",
    "                edge_dict,\n",
    "                n_inp=116,\n",
    "                n_hid=args['n_hid'],\n",
    "                n_out=2,\n",
    "                n_layers=args['n_layers'],\n",
    "                n_heads=args['n_heads']\n",
    "            )\n",
    "        elif self.modeltype == 'HGT':\n",
    "            node_dict = {'area':0}\n",
    "            edge_dict={'func'+str(i):i for i in range(len(self.RSN))}\n",
    "            args = self.args_model\n",
    "            from ModelsForGraph import HGT_v1\n",
    "            self.model=HGT_v1(\n",
    "                node_dict,\n",
    "                edge_dict,\n",
    "                n_inp=116,\n",
    "                n_hid=args['n_hid'],\n",
    "                n_out=2,\n",
    "                n_layers=args['n_layers'],\n",
    "                n_heads=args['n_heads']\n",
    "            )\n",
    "        elif self.modeltype == 'HAN':\n",
    "            from ModelsForGraph import HAN\n",
    "            self.model = HAN(\n",
    "                meta_paths=self.args_model['metapath'],\n",
    "                in_size=116,\n",
    "                hidden_size=self.args_model['n_hid'],\n",
    "                out_size=2,\n",
    "                num_heads=[self.args_model['num_heads']],\n",
    "                dropout=self.args_model['dropout']\n",
    "            )\n",
    "        self.model = self.model.to(device)\n",
    "\n",
    "    def init_optimizer(self):\n",
    "        args = self.args_train\n",
    "        self.optimizer = th.optim.Adam(self.model.parameters(),lr=args['lr'])\n",
    "        self.lr_schedule=CosineLRScheduler(optimizer=self.optimizer,t_initial=50,lr_min=1e-5,warmup_t=5,cycle_limit=1)\n",
    "    \n",
    "    def init_lossfn(self):\n",
    "        self.lossfn =  LabelSmoothingCrossEntropy(self.args_train['losspr'])\n",
    "        self.lossfn = self.lossfn.to(device)\n",
    "\n",
    "    def validate(self):\n",
    "        with th.no_grad():\n",
    "            self.model.eval()\n",
    "            test_pred,test_true,test_pred_prob=[],[],[]\n",
    "            for image,label in self.test_loader:\n",
    "                image=image.to(device)\n",
    "                label=label.to(device)\n",
    "                pred=self.model(image)\n",
    "                test_pred.extend(pred.argmax(dim=1).tolist())\n",
    "                test_true.extend(label.tolist())\n",
    "                test_pred_prob.extend(pred.tolist())\n",
    "            test_acc=accuracy_score(test_true,test_pred)\n",
    "            test_f1=f1_score(test_true,test_pred)\n",
    "            test_true=np.eye(pred.shape[1])[test_true]\n",
    "            test_auc=roc_auc_score(test_true,test_pred_prob)\n",
    "            return test_acc,test_f1,test_auc\n",
    "    \n",
    "    def train(self):\n",
    "        result_acc,result_f1,result_auc=[],[],[]\n",
    "        for train_split,test_split in self.KFold:\n",
    "            self.init_data(train_split,test_split)\n",
    "            self.init_weight()\n",
    "            optimizer = self.optimizer\n",
    "            max_acc,max_f1,max_auc=.0,.0,.0\n",
    "            for epoch in range(self.args_train['epoch']):\n",
    "                self.model.train()\n",
    "                train_loss,train_acc=.0,.0\n",
    "                for image,label in self.train_loader:\n",
    "                    image=image.to(device)\n",
    "                    label=label.to(device)\n",
    "                    pred=self.model(image)\n",
    "                    loss=self.lossfn(pred,label)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    train_loss+=loss.item()\n",
    "                    acc = (pred.argmax(dim=1) == label).float().sum()\n",
    "                    train_acc +=acc.item()\n",
    "                self.lr_schedule.step(epoch)\n",
    "                acc,f1,auc=self.validate()\n",
    "                if (epoch+1)%10==0:\n",
    "                    print('Epoch: {:2d}  Train Loss: {:.4f}  Train Acc:  {:.4F}  Test [Acc:{:.4f} F1:{:.4f} AUC:{:.4f}]'.format(\n",
    "                        epoch+1,train_loss/len(self.train_loader),train_acc/len(self.traindata),acc,f1,auc))\n",
    "                    max_acc=max(acc,max_acc)\n",
    "                    max_f1=max(f1,max_f1)\n",
    "                    max_auc=max(auc,max_auc)\n",
    "            result_acc.append(max_acc)\n",
    "            result_f1.append(max_f1)\n",
    "            result_auc.append(max_auc)\n",
    "            if acc == max_acc or f1 == max_f1:\n",
    "                key=datetime.datetime.strftime(datetime.datetime.now(),'%Y-%m-%d-%H-%M-%S')\n",
    "                path = './checkpoint/'+key+'.pt'\n",
    "                torch.save(self.model.state_dict(),path)\n",
    "        \n",
    "        result_acc=np.array(result_acc)\n",
    "        result_f1=np.array(result_f1)\n",
    "        result_auc=np.array(result_auc)\n",
    "        result='[Acc:{:.3f}+{:.3f}  F1:{:.3f}+{:.3f}  AUC:{:.3f}+{:.3f}]'.format(\n",
    "            np.mean(result_acc),np.std(result_acc),np.mean(result_f1),np.std(result_f1),np.mean(result_auc),np.std(result_auc)\n",
    "        )\n",
    "        print('Final Result',result)\n",
    "        return result,result_acc,result_f1,result_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8a3513f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:696  Test:175  Nodes:116\n",
      "Epoch: 10  Train Loss: 0.6915  Train Acc:  0.4899  Test [Acc:0.6000 F1:0.3137 AUC:0.6144]\n",
      "Epoch: 20  Train Loss: 0.6470  Train Acc:  0.6624  Test [Acc:0.5829 F1:0.4672 AUC:0.6135]\n",
      "Epoch: 30  Train Loss: 0.5292  Train Acc:  0.8204  Test [Acc:0.5886 F1:0.5325 AUC:0.6482]\n",
      "Epoch: 40  Train Loss: 0.4431  Train Acc:  0.9210  Test [Acc:0.6571 F1:0.5775 AUC:0.6592]\n",
      "Epoch: 50  Train Loss: 0.4070  Train Acc:  0.9497  Test [Acc:0.6514 F1:0.5734 AUC:0.6583]\n",
      "Epoch: 60  Train Loss: 0.3845  Train Acc:  0.9698  Test [Acc:0.6514 F1:0.5734 AUC:0.6610]\n",
      "Epoch: 70  Train Loss: 0.3667  Train Acc:  0.9856  Test [Acc:0.6457 F1:0.5694 AUC:0.6593]\n",
      "Epoch: 80  Train Loss: 0.3511  Train Acc:  0.9928  Test [Acc:0.6457 F1:0.5634 AUC:0.6600]\n",
      "Epoch: 90  Train Loss: 0.3404  Train Acc:  0.9943  Test [Acc:0.6400 F1:0.5532 AUC:0.6468]\n",
      "Epoch: 100  Train Loss: 0.3347  Train Acc:  0.9957  Test [Acc:0.6457 F1:0.5571 AUC:0.6441]\n",
      "Train:697  Test:174  Nodes:116\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24327/3662974908.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0margs_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRuner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mmodelresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         result={\n\u001b[1;32m     41\u001b[0m             \u001b[0;34m'args_train'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0margs_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_24327/1344006867.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m                     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlossfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/D/anaconda3/envs/yazid-cuda11/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/D/anaconda3/envs/yazid-cuda11/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import datetime\n",
    "args_train = {\n",
    "    'lr':1e-4,\n",
    "    'losspr':0.2,\n",
    "    'epoch':100,\n",
    "    'template':'BM20.npy'\n",
    "    }\n",
    "args_model={\n",
    "    'model_name':'SEHGT',\n",
    "    'n_hid':384,\n",
    "    'n_layers':8,\n",
    "    'n_heads':12\n",
    "    }\n",
    "\n",
    "\n",
    "# metapath=[]\n",
    "# for i in range(10):\n",
    "#     metapath.append(['func'+str(i)])\n",
    "#     if i == 9:\n",
    "#         break\n",
    "#     for j in range(i+1,10):\n",
    "#         metapath.append(['func'+str(i),'func'+str(j)])\n",
    "# args_HAN={\n",
    "#     'model_name':'HAN',\n",
    "#     'metapath':metapath,\n",
    "#     'n_hid':256,\n",
    "#     'num_heads':8,\n",
    "#     'dropout':0.2\n",
    "# }\n",
    "#args_model = args_HAN\n",
    "\n",
    "\n",
    "for model in ['SEHGT']:\n",
    "    for rsn in ['BM20.npy']:\n",
    "        args_train['template']=rsn\n",
    "        args_model['model_name']=model\n",
    "        main = Runer(args_model=args_model,args_train=args_train)\n",
    "        modelresult,acc,f1,auc=main.train()\n",
    "        result={\n",
    "            'args_train':args_train,\n",
    "            'args_model':args_model,\n",
    "            'Result':modelresult}\n",
    "        if os.path.exists('result.json'):\n",
    "            with open('result.json','r',encoding='utf8')as fp:\n",
    "                json_data = json.load(fp)\n",
    "        else:\n",
    "            json_data={}\n",
    "        key=datetime.datetime.strftime(datetime.datetime.now(),'%Y-%m-%d %H:%M:%S')\n",
    "        json_data[key]=result\n",
    "        with open('result.json','w') as f:\n",
    "            f.write(json.dumps(json_data,ensure_ascii=False,indent=4,separators=(',',':')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8366ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62857143, 0.70689655, 0.67241379, 0.67816092, 0.67816092])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb94e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gcs[-1].selayer.register_forward_hook(hook)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yazid-cuda11",
   "language": "python",
   "name": "yazid-cuda11"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
